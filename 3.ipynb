{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crab', 'dog', 'dolphin', 'elephant', 'human', 'lion', 'snake']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=os.getcwd()+\"/data\"\n",
    "#p=os.getcwd()+\"/prep\"\n",
    "seed=20\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "dir_names = sorted(os.listdir(p))\n",
    "dir_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['crab', 'dog', 'dolphin', 'elephant', 'human', 'lion', 'snake'], 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import splitfolders\n",
    "\n",
    "input_folder = \"data\" \n",
    "output_folder = \"animals_dataset\"\n",
    "\n",
    "splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.8, .2), group_prefix=None)\n",
    "\n",
    "\n",
    "class_names = dir_names\n",
    "class_num=len(class_names)\n",
    "class_names,class_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x:\\Anaconda\\envs\\tens_env\\lib\\site-packages\\keras\\src\\layers\\preprocessing\\data_layer.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.5  Python-3.10.19 torch-2.5.1 CPU (Intel Core i5-10300H 2.50GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=animals_dataset, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=my_animal_model2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\plotv\\Desktop\\\\3\\runs\\classify\\my_animal_model2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\plotv\\Desktop\\\\3\\animals_dataset\\train... found 336 images in 7 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\plotv\\Desktop\\\\3\\animals_dataset\\val... found 85 images in 7 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    339207  ultralytics.nn.modules.head.Classify         [256, 7]                      \n",
      "YOLOv8n-cls summary: 56 layers, 1,447,255 parameters, 1,447,255 gradients\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 7.510.2 MB/s, size: 59.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\plotv\\Desktop\\Инженерия\\3\\animals_dataset\\train... 336 images, 0 corrupt: 100% ━━━━━━━━━━━━ 336/336 595.2it/s 0.6s0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\plotv\\Desktop\\\\3\\animals_dataset\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 11.513.9 MB/s, size: 85.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\plotv\\Desktop\\Инженерия\\3\\animals_dataset\\val... 85 images, 0 corrupt: 100% ━━━━━━━━━━━━ 85/85 781.9it/s 0.1s0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\plotv\\Desktop\\\\3\\animals_dataset\\val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m MuSGD(lr=0.000909, momentum=0.9) with parameter groups 0 weight(decay=0.0), 0 weight(decay=0.0005), 0 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\plotv\\Desktop\\\\3\\runs\\classify\\my_animal_model2\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\plotv\\AppData\\Roaming\\Ultralytics\\Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 1.8MB/s 0.4s/s 0.3s<0.8s\n",
      "\u001b[K       1/20         0G       1.99         16        224: 100% ━━━━━━━━━━━━ 21/21 4.6s/it 1:361.2sss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 1.9it/s 1.6s1.0s\n",
      "                   all      0.141      0.776\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       2/20         0G      1.905         16        224: 100% ━━━━━━━━━━━━ 21/21 2.6s/it 55.1s0.8ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 1.9it/s 1.5s0.9s\n",
      "                   all      0.259      0.941\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       3/20         0G      1.729         16        224: 100% ━━━━━━━━━━━━ 21/21 2.4s/it 50.7s0.7s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 1.9it/s 1.6s1.2s\n",
      "                   all        0.6      0.988\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       4/20         0G      1.494         16        224: 100% ━━━━━━━━━━━━ 21/21 2.0s/it 41.8s0.9s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 1.9it/s 1.6s1.2s\n",
      "                   all      0.871      0.988\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       5/20         0G      1.205         16        224: 100% ━━━━━━━━━━━━ 21/21 1.5s/it 32.4s0.7s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 1.9it/s 1.5s1.1s\n",
      "                   all      0.906          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       6/20         0G     0.9108         16        224: 100% ━━━━━━━━━━━━ 21/21 1.5s/it 32.1s0.6s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 1.9it/s 1.5s1.2s\n",
      "                   all      0.941          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       7/20         0G     0.7006         16        224: 100% ━━━━━━━━━━━━ 21/21 1.5s/it 32.2s0.5s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 1.9it/s 1.6s1.2s\n",
      "                   all      0.929          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       8/20         0G     0.5453         16        224: 100% ━━━━━━━━━━━━ 21/21 1.8s/it 37.2s0.7s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 1.9it/s 1.6s1.2s\n",
      "                   all      0.941          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       9/20         0G     0.4212         16        224: 100% ━━━━━━━━━━━━ 21/21 1.5s/it 32.5s0.6s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 2.0it/s 1.5s1.1s\n",
      "                   all      0.953          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      10/20         0G     0.3558         16        224: 100% ━━━━━━━━━━━━ 21/21 1.5s/it 32.3s0.5s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 2.0it/s 1.5s1.1s\n",
      "                   all      0.965          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      11/20         0G     0.2952         16        224: 100% ━━━━━━━━━━━━ 21/21 1.5s/it 32.2s0.5s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 1.9it/s 1.5s1.1s\n",
      "                   all      0.965          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      12/20         0G     0.2905         16        224: 100% ━━━━━━━━━━━━ 21/21 1.8s/it 37.1s0.7s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 2.0it/s 1.5s1.2s\n",
      "                   all      0.976          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      13/20         0G      0.259         16        224: 100% ━━━━━━━━━━━━ 21/21 1.5s/it 32.3s0.6s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 1.9it/s 1.6s1.3s\n",
      "                   all      0.976          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      14/20         0G     0.2338         16        224: 100% ━━━━━━━━━━━━ 21/21 1.5s/it 32.3s0.6s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 1.8it/s 1.6s1.3s\n",
      "                   all      0.976          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      15/20         0G     0.2336         16        224: 100% ━━━━━━━━━━━━ 21/21 1.5s/it 32.4s0.4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 2.0it/s 1.5s0.9s\n",
      "                   all      0.976          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      16/20         0G       0.21         16        224: 100% ━━━━━━━━━━━━ 21/21 1.7s/it 36.7s0.7s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 1.9it/s 1.5s1.1s\n",
      "                   all      0.976          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      17/20         0G     0.2321         16        224: 100% ━━━━━━━━━━━━ 21/21 1.6s/it 32.6s0.6s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 1.9it/s 1.5s1.1s\n",
      "                   all      0.988          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      18/20         0G     0.2268         16        224: 100% ━━━━━━━━━━━━ 21/21 1.5s/it 32.2s0.5s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 1.9it/s 1.6s1.2s\n",
      "                   all      0.988          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      19/20         0G     0.2326         16        224: 100% ━━━━━━━━━━━━ 21/21 1.5s/it 32.2s0.5s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 1.9it/s 1.6s1.4s\n",
      "                   all      0.988          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      20/20         0G     0.2051         16        224: 100% ━━━━━━━━━━━━ 21/21 1.8s/it 36.8s0.7s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 2.0it/s 1.5s1.0s\n",
      "                   all      0.988          1\n",
      "\n",
      "20 epochs completed in 0.226 hours.\n",
      "Optimizer stripped from C:\\Users\\plotv\\Desktop\\\\3\\runs\\classify\\my_animal_model2\\weights\\last.pt, 3.0MB\n",
      "Optimizer stripped from C:\\Users\\plotv\\Desktop\\\\3\\runs\\classify\\my_animal_model2\\weights\\best.pt, 3.0MB\n",
      "\n",
      "Validating C:\\Users\\plotv\\Desktop\\\\3\\runs\\classify\\my_animal_model2\\weights\\best.pt...\n",
      "Ultralytics 8.4.5  Python-3.10.19 torch-2.5.1 CPU (Intel Core i5-10300H 2.50GHz)\n",
      "YOLOv8n-cls summary (fused): 30 layers, 1,443,847 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\plotv\\Desktop\\\\3\\animals_dataset\\train... found 336 images in 7 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\plotv\\Desktop\\\\3\\animals_dataset\\val... found 85 images in 7 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 3/3 1.9it/s 1.6s1.0s\n",
      "                   all      0.988          1\n",
      "Speed: 0.0ms preprocess, 4.0ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\plotv\\Desktop\\\\3\\runs\\classify\\my_animal_model2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_model():\n",
    "    model = YOLO('yolov8n-cls.pt') \n",
    "\n",
    "    results = model.train(\n",
    "        data=\"animals_dataset\",\n",
    "        epochs=20,\n",
    "        imgsz=224,\n",
    "        batch=16,\n",
    "        name='my_animal_model'\n",
    "    )\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка модели...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "MODEL_PATH = 'runs/classify/my_animal_model2/weights/best.pt' \n",
    "\n",
    "\n",
    "print(\"Загрузка модели...\")\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Can't receive frame.\")\n",
    "    exit()\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    display_frame = frame.copy()\n",
    "\n",
    "    results = model.predict(display_frame, verbose=False, stream=False)\n",
    "\n",
    "    result = results[0]\n",
    "\n",
    "    \n",
    "    top5_indices = result.probs.top5\n",
    "    top5_conf = result.probs.top5conf\n",
    "    \n",
    "\n",
    "    top1_idx = top5_indices[0]\n",
    "    top1_conf = top5_conf[0].item()\n",
    "    top1_name = result.names[top1_idx]\n",
    "\n",
    "\n",
    "    if len(top5_indices) > 1:\n",
    "        top2_idx = top5_indices[1]\n",
    "        top2_conf = top5_conf[1].item()\n",
    "        top2_name = result.names[top2_idx]\n",
    "    else:\n",
    "        top2_name = \"N/A\"\n",
    "        top2_conf = 0.0\n",
    "\n",
    "    cv2.rectangle(display_frame, (0, 0), (400, 100), (0, 0, 0), -1)\n",
    "    \n",
    "    text_1 = f\"1. {top1_name}: {top1_conf * 100:.1f}%\"\n",
    "    cv2.putText(display_frame, text_1, (10, 40), font, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    text_2 = f\"2. {top2_name}: {top2_conf * 100:.1f}%\"\n",
    "    cv2.putText(display_frame, text_2, (10, 80), font, 0.8, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    fps = 1.0 / (time.time() - start_time)\n",
    "    cv2.putText(display_frame, f\"FPS: {fps:.1f}\", (10, 130), font, 0.6, (200, 200, 200), 1)\n",
    "\n",
    "    cv2.imshow(\"Animal Classifier\", display_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка моделей...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "\n",
    "CLASSIFIER_PATH = 'runs/classify/my_animal_model2/weights/best.pt'\n",
    "\n",
    "DETECTOR_PATH = 'yolov8n.pt' \n",
    "\n",
    "\n",
    "\n",
    "print(\"Загрузка моделей...\")\n",
    "detector = YOLO(DETECTOR_PATH)\n",
    "classifier = YOLO(CLASSIFIER_PATH)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Can't receive frame.\")\n",
    "    exit()\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    display_frame = frame.copy()\n",
    "    \n",
    "    det_results = detector.predict(frame, verbose=False, conf=0.4)\n",
    "    \n",
    "    best_box = None\n",
    "    max_area = 0\n",
    "\n",
    "    if len(det_results[0].boxes) > 0:\n",
    "        for box in det_results[0].boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "            \n",
    "            area = (x2 - x1) * (y2 - y1)\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                best_box = (x1, y1, x2, y2)\n",
    "\n",
    "    if best_box:\n",
    "        x1, y1, x2, y2 = best_box\n",
    "        \n",
    "        h, w, _ = frame.shape\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = min(w, x2), min(h, y2)\n",
    "\n",
    "        object_crop = frame[y1:y2, x1:x2]\n",
    "\n",
    "        if object_crop.size > 0:\n",
    "            cls_results = classifier.predict(object_crop, verbose=False)\n",
    "            \n",
    "            probs = cls_results[0].probs\n",
    "            top1_idx = probs.top1\n",
    "            conf = probs.top1conf.item()\n",
    "            class_name = cls_results[0].names[top1_idx]\n",
    "\n",
    "\n",
    "            cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "\n",
    "            label = f\"{class_name}: {conf*100:.1f}%\"\n",
    "            \n",
    "            (tw, th), _ = cv2.getTextSize(label, font, 0.8, 2)\n",
    "            cv2.rectangle(display_frame, (x1, y1 - 30), (x1 + tw, y1), (0, 255, 0), -1)\n",
    "            cv2.putText(display_frame, label, (x1, y1 - 5), font, 0.8, (0, 0, 0), 2)\n",
    "            \n",
    "            try:\n",
    "                debug_crop = cv2.resize(object_crop, (150, 150))\n",
    "                display_frame[10:160, 10:160] = debug_crop\n",
    "                cv2.rectangle(display_frame, (10, 10), (160, 160), (255, 255, 255), 1)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    else:\n",
    "\n",
    "        cv2.putText(display_frame, \"Searching for animal...\", (20, 50), font, 1, (0, 0, 255), 2)\n",
    "\n",
    "    fps = 1.0 / (time.time() - start_time)\n",
    "    cv2.putText(display_frame, f\"FPS: {fps:.1f}\", (display_frame.shape[1] - 150, 40), font, 0.7, (200, 200, 200), 2)\n",
    "\n",
    "    cv2.imshow(\"Smart Animal Classifier\", display_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tens_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
